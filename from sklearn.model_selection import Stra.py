from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone # To create independent copies of the model for each fold
from sklearn.metrics import roc_auc_score # Example scorer
from sklearn.pipeline import Pipeline # Useful for chaining steps
import numpy as np

def cross_validate_model(model, X, y, scorer, n_splits=10, random_state=42):
    """
    Perform cross-validation on a given scikit-learn compatible model.

    Uses StratifiedKFold to ensure class proportions are maintained in each fold,
    which is important for potentially imbalanced datasets.

    Args:
        model: The machine learning model instance (must be cloneable, e.g., scikit-learn estimator).
        X (np.ndarray): The input features (entire training set).
        y (np.ndarray): The target values (entire training set).
        scorer (callable): A scoring function (e.g., roc_auc_score, accuracy_score)
                           following the convention scorer(y_true, y_pred_or_proba).
                           Note: Check if your scorer needs predicted labels or probabilities.
        n_splits (int): The number of folds for cross-validation.
        random_state (int): Seed for the KFold split for reproducibility.

    Returns:
        tuple: A tuple containing the mean score and standard deviation of scores across the folds.
               Returns (np.nan, np.nan) if an error occurs.
    """
    # Initialize StratifiedKFold
    # shuffle=True is important to randomize data order before splitting
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    scores = [] # List to store the score for each fold

    # For each split generated by skf.split(X, y):
    # 1. Get the training and validation indices (train_idx, val_idx).
    # 2. Create the training data (X_train_fold, y_train_fold) and validation data (X_val_fold, y_val_fold) using these indices.
    # 3. Create a fresh clone of the original model (use `clone(model)`). Why clone? To ensure each fold trains an independent model from scratch.
    # 4. Fit the cloned model on the fold's training data (X_train_fold, y_train_fold).
    # 5. Make predictions on the fold's validation data (X_val_fold). Decide if you need predict() or predict_proba() based on the scorer.
    #    - For roc_auc_score, you typically need probabilities of the positive class: model.predict_proba(X_val_fold)[:, 1]
    #    - For accuracy_score, you need class labels: model.predict(X_val_fold)
    # 6. Calculate the score using the scorer function with the validation true labels (y_val_fold) and the predictions.
    # 7. Append the calculated score to the `scores` list.

    # 8: Calculate mean and std dev

    print(f"Starting {n_splits}-fold cross-validation...")
    for i, (train_index, test_index) in enumerate(skf.split(X, y)):
        train_idx = train_index
        test_idx = test_index
        X_train_fold = X[train_idx]
        y_train_fold = y[train_idx]
        X_val_fold = X[test_idx]
        y_val_fold = y[test_idx]
        cloned_model = clone(model)
        cloned_model.fit(X_train_fold, y_train_fold)
        if scorer == roc_auc_score:
            y_pred = cloned_model.predict_proba(X_val_fold)[:, 1]
        else:
            y_pred = cloned_model.predict(X_val_fold)

        score = scorer(y_val_fold, y_pred)
        scores.append(score)

    mean_score = np.mean(scores)
    std_score = np.std(scores)

    print(f"Cross-validation finished.")
    print(f"Mean Score: {mean_score:.4f}")
    print(f"Std Dev Score: {std_score:.4f}")

    # 9: Return results
    return mean_score, std_score

# --- Example Usage ---
from sklearn.linear_model import LogisticRegression

# Use the scaled data loaded earlier
# Create a default Logistic Regression model instance
# Note: We don't need the Pipeline here because X_train is already scaled.
log_reg_model = LogisticRegression(random_state=42, max_iter=1000)

# Perform cross-validation using ROC AUC as the scorer
mean_auc, std_auc = cross_validate_model(log_reg_model, X_train, y_train, roc_auc_score, n_splits=5) # Using 5 folds for speed here

print(f"\nLogistic Regression CV Results (ROC AUC): Mean={mean_auc:.4f}, Std={std_auc:.4f}")